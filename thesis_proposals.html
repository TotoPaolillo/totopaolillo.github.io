<!DOCTYPE html>
<html>
<body style="background-color: rgb(255, 255, 255);">

<style>
table, th, td {
 background-color:rgb(255, 255, 255);
}
img {
  border-radius: 5%;
}

table2, th, td {
  border: ;
}
 
body {
  font-family: sans-serif;
  font-size: 90%;
}
 
.div_head {
  font-size: 110%;
  text-align: center;
  height: 50%;  
  padding: 10px;
  border: 2px solid blue;
  box-sizing: border-box;
}
 
.div_head_2 {
  font-size: 100%;
  text-align: justify;
  height: 50%;  
  padding: 10px;
  border: 2px solid blue;
  box-sizing: border-box;
}

</style>

<br>

<table valign="top" align="center" style="max-width:900px;">
<tbody> 
<tr>
<td valign="middle"> 
<img alt="antonio paolillo" src="antonio_paolillo.png" align="middle">
</td>

<td> &nbsp;&nbsp; </td>

<td valign="middle"> 

<h2 style="color:blue;"> Antonio Paolillo </p>
<h3 style="color:blue;"> Researcher </h2>

IDSIA Dalle Molle Institute for Artificial Intelligence, USI-SUPSI

<br>
Lugano, Switzerland

<br><br>
antonio [dot] paolillo [at] idsia.ch / supsi.ch

<br><br>
<a href="https://scholar.google.com/citations?user=9yjlY5gAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a>
 &#8226;  
<a href="https://www.linkedin.com/in/antonio-paolillo-3266b7187" target="_blank">Linkedin</a>
 &#8226; 
<a href="CV_eng_short.pdf" target="_blank"> CV </a>

</td>
</tbody>
</tr>
</table>
 
<table valign="top" align="center" style="max-width:800px;">
<tbody>
<tr>
<td>
 
<br>
Go to <a href="index.html"> home </a>
<br>
<br>

<div class="div_head_2"> <h3 style="color:blue;">Thesis Proposals</h3> </div>
<br>

</td>
</tbody>
</tr>
</table>

<table valign="top" align="center" style="max-width:800px;">

<tbody>

<tr>
<td>

<div class="div_head_2" style="line-height:1.5em" > 

<p style="text-align:center;">
<h3 style="color:blue;text-align:center;">Neural Perception for Visual Servoing</h3> 
<img alt="VS+NN_bd_new" src="documents/VS+NN_bd_new.png" align="middle" width="750px">
</p>
  
Standard image processing techniques implement feature extractions to provide the Visual Servoing (VS) scheme
with proper feedback. Examples of visual features are points, lines, and image moments, which are visible on the
image captured by camera sensors. However, in order to be more adaptive and comply with unstructured scenes,
recent trends in the VS community investigate direct approaches, that treat the entire image as feedback.

<br>
<br>
 
In a previous work [1], we used an artificial Neural Network (NN) that is trained using the information of the
control structure to compute visual features from raw images (see Fig. above). In this thesis proposal we will 
build on these ideas to (i) realize complex VS experiments, tracking objects with complicated shapes and appearance
and (ii) extend the previous architecture to realize a more efficient scheme of machine learning.

<h4>Keywords</h4> 
 
Neural network, self-supervised learning, visual servoing, perception for control.

<h4>Requirements</h4> 
<ul>
 <li> Python programming skills
 <li> Knowledge of ROS (or ROS2)
 <li> Familiarity with Pythorch
</ul>
 
<h4> References</h4> 
 
[1] A. Paolillo, M. Nava, D. Piga, A. Giusti, “Visual Servoing with Geometrically Interpretable Neural Perception,” in IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, 2022, pp. 5300–5306
 
<h4> Useful links </h4> 
 
<ul>
 <li> <a href="https://arxiv.org/pdf/2210.10549.pdf" target="_blank">Pdf of the paper</a>
 <li> <a href="www.youtube.com/watch?v=7ogrFxyl2wI" target="_blank">Video of the experiments</a>
 <li> <a href="documents/graph_abstract_iros22.pdf" target="_blank">Graphical abstract</a>
</ul>

</div>
</td>
</tbody>
</tr>
</table>

 

<table valign="top" align="center" style="max-width:800px;">

<tbody>

<tr>
<td>

<div class="div_head_2" style="line-height:1.5em" > 

<p style="text-align:center;">
<h3 style="color:blue;text-align:center;">Imitation Learning for Visual Servoing with Aerial Drones</h3> 
<p style="text-align:center;">
<img alt="camera_and_traj" src="documents/camera_and_traj.png" align="middle" width="400px">
</p>

 
<br>
 
Impressive results demonstrated the great abilities of aerial drones in performing agile, aggressive, and fast maneuvers.
This is made possible thanks to fast and predictive control paradigms. The combination of these schemes with visual
perception allows these robots to comply with dynamic environments. However, these complex frameworks often conflict
with the computational resources of robots. Furthermore, planning or
predictive schemes are difficult to implement and require fine-tuning. To overcome these issues, one could ‘simply’ imitate
complex trajectories, previously demonstrated and saved in datasets, rather than explicitly implement them.

<br>
<br>

In previous work [1], [2], we have shown how it is possible to apply the Dynamical System(DS)-based Imitation Learning
(IL) to the Visual Servoing (VS) case. Combining DS and VS is beneficial for both the techniques. On the one side, it
allows to include exteroception into the DS, thus adding adaptability; on the other, it allows to avoid specific programming
of additional tasks into the VS. In this thesis, we want to investigate this kind of approaches on aerial nano-drones. The
successful application of DS-based VS on nano-drones would allow to achieve high performing and adaptive maneuvers
without the need of implementing complex and computationally expensive trajectory generators.

<h4>Keywords</h4> 

Machine learning, visual servoing, imitation learning, dynamical systems.

<h4>Requirements</h4> 
<ul> 
 <li> Python programming skills
 <li> Knowledge of ROS (or ROS2)
 <li> Familiarity with machine learning inference methods, such as GPR or GMR
</ul>
 
<h4> References</h4> 
 
[1] A. Paolillo and M. Saveriano, “Learning Stable Dynamical Systems for Visual Servoing,” IEEE Int. Conf. on Robotics
and Automation, 2022, pp. 8636–8642. 
<br>
[2] A. Paolillo, P. Robuffo Giordano, M. Saveriano, “Dynamical System-based Imitation Learning for Visual Servoing using
the Large Projection Formulation,” IEEE Int. Conf. on Robotics and Automation, 2023, to appear.
 
<h4> Useful links </h4> 
 
<ul>
 <li> <a href="https://hal.inria.fr/hal-04019727/document" target="_blank">Pdf of the ICRA23 paper</a>
 <li> <a href="https://youtu.be/L7TylqXmGWM" target="_blank">Video of the ICRA23 experiments</a>
 <li> <a href="https://arxiv.org/pdf/2204.05681.pdf" target="_blank">Pdf of the ICRA22 paper</a>
 <li> <a href=" https://www.youtube.com/watch?v=7ogrFxyl2wI" target="_blank">Video of the ICRA22 experiments</a>
</ul>

</div>
</td>
</tbody>
</tr>
</table>



<table valign="top" align="center" style="max-width:800px;">

<tbody>

<tr>
<td>

<div class="div_head_2" style="line-height:1.5em" > 

<p style="text-align:center;">
<h3 style="color:blue;text-align:center;">Respecting Constraints in Fast Fredictive VS scheme</h3> 
</p>
<p style="text-align:center;">
<img alt="VS_RG_bd" src="documents/VS_RG_bd.png" align="middle" width="700px">
</p>
 
<br>
 
The generation of efficient robotic motion is the object of lively research activities. The benefits introduced by
predictive controllers, such as model predictive control, have to be carefully balanced with the fast execution requirements
of robot controllers. In previous work [1], which focused on visual servoing, we applied the reference governor technique
to embed the anticipatory behavior in the reference signal of the reactive controller. In practice, the original controller
remains untouched, and a reference governor block, implemented as a model predictive control, is put upstream to the
original control loop (see Fig. above). In this way, the MPC only computes the references for the original controller
and can run at a relatively low frequency, while the fast dynamics is delegated to the reactive controller.

<br>
<br>
    
The RG uses the model of the closed-loop VS behavior to make predictions and compute proper references. Furthermore, 
if the prediction is accurate, it can compute novel references for the VS in a way that constraints can be respected
by the VS law. However, in our previous work, this aspect has not been deeply investigated, and this Thesis proposes to
analyse the handling of the constraints in the framework sketched in the Figure within simulation and experimental environments.

<h4>Keywords</h4> 

Visual servoing, model predictive control, reference governor, optimization.

<h4>Requirements</h4> 
<ul> 
 <li> Python programming skills
 <li> Knowledge of ROS (or ROS2)
 <li> Hands-on experience with simulated environments, and robotic platforms
</ul>
 
<h4> References</h4> 
 
[1] A. Paolillo, M. Forgione, D. Piga, E. Mingo Hoffman, “Fast Predictive Visual Servoing: a Reference Governor-based
Approach,” Control Engineering Practice, 2023.
 
<h4> Useful links </h4> 
 
<ul>
 <li> <a href="https://www.sciencedirect.com/science/article/pii/S0967066123000904/pdf" target="_blank">Pdf of the paper</a>
 <li> <a href="https://www.sciencedirect.com/science/article/pii/S0967066123000904?via%3Dihub#mmc1" target="_blank">Video of the experiments</a>
</ul>

</div>
</td>
</tbody>
</tr>
</table>
